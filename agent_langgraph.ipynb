{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998d81ab-0db2-4aa4-9af2-8fcf0691ed06",
   "metadata": {},
   "source": [
    "# Build an agent with LangGraph\n",
    "\n",
    "By themselves, LLMs cannot take **actions** - they just output text. Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs to pass them. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish.\n",
    "\n",
    "In this notebook, we will build an agent in LangGraph that can:\n",
    "\n",
    "- Answer common questions by searching the web\n",
    "- Maintain conversation state across calls\n",
    "- Route complex queries to a human for review\n",
    "- Use custom state to control its behavior\n",
    "- Rewind and explore alternative conversation paths\n",
    "\n",
    "We'll start with a basic chatbot and progressively add more sophisticated capabilities, introducing key LangGraph concepts along the way.\n",
    "\n",
    "> The code in this notebook is adapted from [Introduction to LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/).\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before we begin, please make sure you have setup the `.env` file in the project \n",
    "directory as described in [`README.md`](README.md).\n",
    "\n",
    "Next, we will load in the necessary environment variables for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cbaacb-305b-49b5-b76c-cfc25b14909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "assert os.environ.get(\"GOOGLE_API_KEY\")\n",
    "assert os.environ.get(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a889265b-6924-43e3-b348-106b209a9fe4",
   "metadata": {},
   "source": [
    "## Part 1: Build a Basic Chatbot\n",
    "\n",
    "We'll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, we will have a built rudimentary chatbot.\n",
    "\n",
    "Start by creating a `StateGraph`. A `StateGraph` object defines the structure of our chatbot as a \"state machine\". We'll add `nodes` to represent the llm and functions our chatbot can call and `edges` to specify how the bot should transition between these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6676198-cead-467a-916e-1aee13a602c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816b48b-1444-4a1c-93e2-460c8cf792ea",
   "metadata": {},
   "source": [
    "**Notice** that we've defined our `State` as a TypedDict with a single key: `messages`. The `messages` key is annotated with the [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function, which tells LangGraph to append new messages to the existing list, rather than overwriting it.\n",
    "\n",
    "So now our graph knows two things:\n",
    "\n",
    "1. Every `node` we define will receive the current `State` as input and return a value that updates that state.\n",
    "2. `messages` will be _appended_ to the current list, rather than directly overwritten. This is communicated via the prebuilt [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function in the `Annotated` syntax.\n",
    "\n",
    "Next, add a \"`chatbot`\" node. Nodes represent units of work. They are typically regular Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01038f5c-e268-4518-83a1-0f6cf7d85383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74563a4-7298-4a67-9e5c-50113fdfbfe6",
   "metadata": {},
   "source": [
    "**Notice** how the `chatbot` node function takes the current `State` as input and returns an updated `messages` list. This is the basic pattern for all LangGraph node functions.\n",
    "\n",
    "The `add_messages` function in our `State` will append the llm's response messages to whatever messages are already in the state.\n",
    "\n",
    "Next, add an `entry` point. This tells our graph **where to start its work** each time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13016c0f-54e8-406f-a073-bf8d66722f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77e29c-d1c3-4e0d-abdb-7103b3b08331",
   "metadata": {},
   "source": [
    "Similarly, set a `finish` point. This instructs the graph **\"any time this node is run, you can exit.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e9814f9-0c88-4b47-b0ac-c9601859177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.set_finish_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed0e39-bfac-49c4-a60f-d4e2b01c7b02",
   "metadata": {},
   "source": [
    "Finally, we'll want to be able to run our graph. To do so, call \"`compile()`\" on the graph builder. This creates a \"`CompiledGraph`\" we can use invoke on our state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ed7f37-0ce2-4cec-9822-312d620fd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f1c6f-250d-464f-af77-1c705a77c9cc",
   "metadata": {},
   "source": [
    "You can visualize the graph using the `get_graph` method and one of the \"draw\" methods, like `draw_ascii` or `draw_png`. The `draw` methods each require additional dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3abb8d-c960-49c3-aa87-11d58a5bd22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f431d-3bff-4bc4-9361-f119b7de52de",
   "metadata": {},
   "source": [
    "Now let's run the chatbot! \n",
    "\n",
    "**Tip:** You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17768906-55ea-44ee-b655-49fd1632b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the weather in Kuala Lumpur?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I do not have access to real-time information, including weather. To get the current weather in Kuala Lumpur, I recommend checking a reliable weather website or app. \n",
      "\n",
      "Here are some popular options:\n",
      "\n",
      "* **AccuWeather:** [https://www.accuweather.com/](https://www.accuweather.com/)\n",
      "* **The Weather Channel:** [https://weather.com/](https://weather.com/)\n",
      "* **Weather Underground:** [https://www.wunderground.com/](https://www.wunderground.com/)\n",
      "* **Google Weather:** [https://www.google.com/search?q=weather+kuala+lumpur](https://www.google.com/search?q=weather+kuala+lumpur) \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:    \n",
    "    \n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "        \n",
    "    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce29aa-a076-45a1-9ac3-5750ff6cfbcd",
   "metadata": {},
   "source": [
    "**Congratulations!** We've built our first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM.\n",
    "\n",
    "However, the bot's knowledge is limited to what's in its training data. In the next part, we'll add a web search tool to expand the chatbot's knowledge and make it more capable.\n",
    "\n",
    "Below is the full code for this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b3427db-8763-47f3-9600-87a8763ede12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be \n",
    "# called whenever the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a0962-410a-4171-b995-7c5076f1990f",
   "metadata": {},
   "source": [
    "## Part 2: Enhancing the Chatbot with Tools\n",
    "\n",
    "To handle queries our chatbot can't answer \"from memory\", we'll integrate a web search tool [Tavily Search API](https://tavily.com/). Our chatbot can use this tool to find relevant information and provide better responses.\n",
    "\n",
    "See also: [LangChain tools - Tavily Search](https://python.langchain.com/v0.2/docs/integrations/tools/tavily_search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e7bb7e-5128-42b1-ac42-c61bde14f52d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.meteoprog.com/weather/Kualalumpur/month/june/',\n",
       "  'content': 'Kuala Lumpur (Malaysia) weather in June 2024 ☀️ Accurate weather forecast for Kuala Lumpur in June ⛅ Detailed forecast By month Current temperature \"near me\" Weather news ⊳ Widget of weather ⊳ Water temperature | METEOPROG. Meteoprog.com. ... 25 June +32 °+24° 26 June +32° ...'},\n",
       " {'url': 'https://www.weatherapi.com/',\n",
       "  'content': \"{'location': {'name': 'Kuala Lumpur', 'region': 'Kuala Lumpur', 'country': 'Malaysia', 'lat': 3.17, 'lon': 101.7, 'tz_id': 'Asia/Kuala_Lumpur', 'localtime_epoch': 1719286876, 'localtime': '2024-06-25 11:41'}, 'current': {'last_updated_epoch': 1719286200, 'last_updated': '2024-06-25 11:30', 'temp_c': 30.0, 'temp_f': 86.1, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 2.9, 'wind_kph': 4.7, 'wind_degree': 172, 'wind_dir': 'S', 'pressure_mb': 1009.0, 'pressure_in': 29.8, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 62, 'cloud': 23, 'feelslike_c': 33.6, 'feelslike_f': 92.4, 'windchill_c': 30.1, 'windchill_f': 86.1, 'heatindex_c': 33.6, 'heatindex_f': 92.4, 'dewpoint_c': 22.0, 'dewpoint_f': 71.7, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 8.0, 'gust_mph': 3.4, 'gust_kph': 5.4}}\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tool.invoke(\"What is the weather in Kuala Lumpur?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec8067-09ae-4803-b219-db629dcb48b2",
   "metadata": {},
   "source": [
    "The results are page summaries our chat bot can use to answer questions.\n",
    "\n",
    "Next, we'll start defining our graph. The following is all **the same as in Part 1**, except we have added `bind_tools` on our LLM. This lets the LLM know the correct JSON format to use if it wants to use our search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e44aef-3a5a-464b-a23e-c8957bdb9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ecd1f-3c3a-4e23-a952-d0776fc93f55",
   "metadata": {},
   "source": [
    "Next we need to create a function to actually run the tools if they are called. We'll do this by adding the tools to a new node.\n",
    "\n",
    "Below, implement a `BasicToolNode` class that checks the most recent message in the state and calls tools if the message contains `tool_calls`. It relies on the LLM's `tool_calling` support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\n",
    "\n",
    "Later, we will replace this with LangGraph's prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) to speed things up, but building it ourselves first is helpful to see what is going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e769b9e-c9cc-411f-8d80-902ab67d6b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):        \n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "            \n",
    "        outputs = []\n",
    "        \n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool = self.tools_by_name[tool_name]\n",
    "            tool_args = tool_call[\"args\"]\n",
    "            tool_result = tool.invoke(tool_args)\n",
    "                        \n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_name,\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        return {\"messages\": outputs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b3fb334-5b6f-41c1-a971-8669350c5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae5849-7429-452d-b3ac-c7935d00298e",
   "metadata": {},
   "source": [
    "With the tool node added, we can define the `conditional_edges`. \n",
    "\n",
    "Recall that **edges** route the control flow from one node to the next. **Conditional edges** usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph `state` and return a string or list of strings indicating which node(s) to call next.\n",
    "\n",
    "Below, call define a router function called `route_tools`, that checks for tool_calls in the chatbot's output. Provide this function to the graph by calling `add_conditional_edges`, which tells the graph that whenever the `chatbot` node completes to check this function to see where to go next. \n",
    "\n",
    "The condition will route to `tools` if tool calls are present and \"`__end__`\" if not.\n",
    "\n",
    "Later, we will replace this with the prebuilt [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition) to be more concise, but implementing it ourselves first makes things more clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e3eaf97-57f7-42d1-b69d-8a03055644b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    ") -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "        \n",
    "    if (hasattr(ai_message, \"tool_calls\") and \n",
    "        len(ai_message.tool_calls) > 0):        \n",
    "        return \"tools\"        \n",
    "    return \"__end__\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2580a5a8-66f3-4ea8-bc37-b7297d51b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `route_tools` function returns \"tools\" if the chatbot asks to use a tool, and \"__end__\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    \n",
    "    # The following dictionary lets you tell the graph to interpret \n",
    "    # the condition's outputs as a specific node.\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\n",
    "        \"tools\": \"tools\", \n",
    "        \"__end__\": \"__end__\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3021d4f4-59b2-4939-827a-fa23c18870c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7144cb-3cd3-48b5-bdb5-26ec73d9b02e",
   "metadata": {},
   "source": [
    "**Notice** that conditional edges start from a single node. This tells the graph \"any time the '`chatbot`' node runs, either go to 'tools' if it calls a tool, or end the loop if it responds directly. \n",
    "\n",
    "Like the prebuilt `tools_condition`, our function returns the \"`__end__`\" string if no tool calls are made. When the graph transitions to `__end__`, it has no more tasks to complete and ceases execution. Because the condition can return `__end__`, we don't need to explicitly set a `finish_point` this time. Our graph already has a way to finish!\n",
    "\n",
    "Let's visualize the graph we've built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5014b29-a4f0-4e3d-a82c-b5b1c1fff1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d0f44-4b9f-464d-807b-282ed0e8dd80",
   "metadata": {},
   "source": [
    "Now we can ask the bot questions outside its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a83253d-0ce1-4bf5-9e62-c0e0c8d7d4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the weather in Kuala Lumpur?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "Assistant: [{\"url\": \"https://www.meteoprog.com/weather/Kualalumpur/month/june/\", \"content\": \"Kuala Lumpur (Malaysia) weather in June 2024 \\u2600\\ufe0f Accurate weather forecast for Kuala Lumpur in June \\u26c5 Detailed forecast By month Current temperature \\\"near me\\\" Weather news \\u22b3 Widget of weather \\u22b3 Water temperature | METEOPROG ... 25 June +32 \\u00b0+24\\u00b0 26 June +32\\u00b0 ...\"}, {\"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'Kuala Lumpur', 'region': 'Kuala Lumpur', 'country': 'Malaysia', 'lat': 3.17, 'lon': 101.7, 'tz_id': 'Asia/Kuala_Lumpur', 'localtime_epoch': 1719287567, 'localtime': '2024-06-25 11:52'}, 'current': {'last_updated_epoch': 1719287100, 'last_updated': '2024-06-25 11:45', 'temp_c': 30.0, 'temp_f': 86.1, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 2.9, 'wind_kph': 4.7, 'wind_degree': 172, 'wind_dir': 'S', 'pressure_mb': 1009.0, 'pressure_in': 29.8, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 62, 'cloud': 23, 'feelslike_c': 33.6, 'feelslike_f': 92.4, 'windchill_c': 30.1, 'windchill_f': 86.1, 'heatindex_c': 33.6, 'heatindex_f': 92.4, 'dewpoint_c': 22.0, 'dewpoint_f': 71.7, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 8.0, 'gust_mph': 3.4, 'gust_kph': 5.4}}\"}]\n",
      "Assistant: The weather in Kuala Lumpur is currently Sunny with a temperature of 30.0 degrees Celsius. It feels like 33.6 degrees Celsius. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Will it rain there today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I am sorry, I cannot fulfill this request. The available tools lack the functionality to provide weather information. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    \n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "        \n",
    "    for event in graph.stream(\n",
    "        {\n",
    "            \"messages\": [(\"user\", user_input)]\n",
    "        }\n",
    "    ):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50484a45-4332-46bf-854c-c6bb9391451b",
   "metadata": {},
   "source": [
    "**Congrats!** We've created a conversational agent in LangGraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries.\n",
    "\n",
    "Our chatbot still can't remember past interactions on its own, limiting its ability to have coherent, multi-turn conversations. In the next part, we'll add **memory** to address this.\n",
    "\n",
    "The full code for the graph we've created in this section is reproduced below, replacing our `BasicToolNode` for the prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode), and our `route_tools` condition with the prebuilt [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0480e130-b1e1-4740-bfce-5bafb5361acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090913ad-2415-4391-8b7f-001bd4093fa6",
   "metadata": {},
   "source": [
    "## Part 3: Adding Memory to the Chatbot\n",
    "\n",
    "Our chatbot can now use tools to answer user questions, but it doesn't remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\n",
    "\n",
    "LangGraph solves this problem through **persistent checkpointing**. If you provide a `checkpointer` when compiling the graph and a `thread_id` when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same `thread_id`, the graph loads its saved state, allowing the chatbot to pick up where it left off. \n",
    "\n",
    "To get started, create a `SqliteSaver` checkpointer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54f375ed-fd6c-4bbb-8ecd-d74fd5672039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e328f-dc31-4282-b4fd-de3e3c98f4f3",
   "metadata": {},
   "source": [
    "**Notice** that we've specified `:memory` as the Sqlite DB path. This is convenient for our notebook (it saves it all in-memory). In a production application, you would likely change this to connect to your own DB and/or use one of the other checkpointer classes.\n",
    "\n",
    "Next define the graph. Now that you've already built your own `BasicToolNode`, we'll replace it with LangGraph's prebuilt `ToolNode` and `tools_condition`, since these do some nice things like parallel API execution. Apart from that, the following is all copied from Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1390e94c-de54-49bf-b186-376046da4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb64f826-d2fa-4f1f-a106-88ce25f8262c",
   "metadata": {},
   "source": [
    "Finally, compile the graph with the provided checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f6b8ee2-d607-4b6d-9f22-b56f75c1e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ec2c6-5cb6-41e5-9229-395e63ae10c6",
   "metadata": {},
   "source": [
    "Notice the graph hasn't changed since Part 2. All we are doing is checkpointing the `State` as the graph works through each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76937090-7179-4a12-ba9d-750aa5b56bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81b92e-59f8-4846-95fe-2a7ee9db59c9",
   "metadata": {},
   "source": [
    "Now we can interact with our bot! First, pick a thread to use as the key for this conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bde5c345-b966-4501-a910-eaff73a4e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c1b60b-60a1-424d-a0b4-00f8f76589c8",
   "metadata": {},
   "source": [
    "Next, call our chat bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd32759a-794b-4fee-a1b1-274a1b99a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Ken.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Ken, nice to meet you! 👋  What can I do for you today?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hi there! My name is Ken.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    input={\n",
    "        \"messages\": [(\"user\", user_input)]\n",
    "    }, \n",
    "    config=config, \n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721090dc-0106-4852-8adf-56fe2d546705",
   "metadata": {},
   "source": [
    "**Note:** The config was provided as the **second positional argument** when calling our graph. It importantly is _not_ nested within the graph inputs (`{'messages': []}`).\n",
    "\n",
    "Let's ask a followup: see if it remembers your name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e57bcf2d-454d-4720-82a7-b85e1d0a168f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I will try my best to remember your name, Ken! 😊  Is there anything else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    input = {\n",
    "        \"messages\": [(\"user\", user_input)]\n",
    "    }, \n",
    "    config=config, \n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08a915-e91c-4a1c-9089-ffd51de60c67",
   "metadata": {},
   "source": [
    "**Notice** that we aren't using an external list for memory – it's all handled by the checkpointer!\n",
    "\n",
    "Try using a different `thread_id` in the `config` argument and see if it remembers your name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f08c223d-1ad8-4357-ac69-57543a5f0af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I am sorry, I do not have memory of past conversations. If you would like to tell me your name, I can remember it for this conversation. What is your name?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    input={\n",
    "        \"messages\": [(\"user\", user_input)]\n",
    "    },\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            # Only difference is we change the `thread_id` \n",
    "            # to \"2\" instead of \"1\"\n",
    "            \"thread_id\": \"2\"\n",
    "        }\n",
    "    },\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8768b2-53b2-4024-9173-18710af3c5ed",
   "metadata": {},
   "source": [
    "**Notice** that the **only** change we've made is to modify the `thread_id` in the config.\n",
    "\n",
    "By now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph's `state` for a given config at any time, call `get_state(config)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5276359b-647e-4d42-a3db-c9782ba9ad10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Ken.', id='efa2a6d6-d140-48d6-9604-b42d6adc0df2'), AIMessage(content='Hi Ken, nice to meet you! 👋  What can I do for you today? \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-bad3872b-e569-41b6-a2fa-92b9b2131f92-0', usage_metadata={'input_tokens': 82, 'output_tokens': 18, 'total_tokens': 100}), HumanMessage(content='Remember my name?', id='ed4c40a7-4bb1-40e2-8fc5-853822f17005'), AIMessage(content='I will try my best to remember your name, Ken! 😊  Is there anything else I can help you with? \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-2a01cf6c-9f9f-4a2f-acc0-ceec6c853055-0', usage_metadata={'input_tokens': 108, 'output_tokens': 24, 'total_tokens': 132})]}, next=(), config={'configurable': {'thread_id': '1', 'thread_ts': '1ef32a71-bef4-6b52-8004-f1db115a9480'}}, metadata={'source': 'loop', 'step': 4, 'writes': {'chatbot': {'messages': [AIMessage(content='I will try my best to remember your name, Ken! 😊  Is there anything else I can help you with? \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-2a01cf6c-9f9f-4a2f-acc0-ceec6c853055-0', usage_metadata={'input_tokens': 108, 'output_tokens': 24, 'total_tokens': 132})]}}}, created_at='2024-06-25T03:57:58.136888+00:00', parent_config={'configurable': {'thread_id': '1', 'thread_ts': '1ef32a71-b704-696a-8003-133201cb632b'}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config) # config for thread_id = 1\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96ef7301-ba6c-4978-a5b7-313cf2c10132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the graph ended this turn, `next` is empty. \n",
    "# If you fetch a state from within a graph invocation, \n",
    "# next tells which node will execute next.\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab80be7-e526-4132-83b2-782954ffdebc",
   "metadata": {},
   "source": [
    "The snapshot above contains the current state values, corresponding config, and the `next` node to process. In our case, the graph has reached an `__end__` state, so `next` is empty.\n",
    "\n",
    "**Congratulations!** Our chatbot can now maintain conversation state across sessions thanks to LangGraph's checkpointing system. This opens up exciting possibilities for more natural, contextual interactions. LangGraph's checkpointing even handles **arbitrarily complex graph states**, which is much more expressive and powerful than simple chat memory.\n",
    "\n",
    "In the next part, we'll introduce human oversight to our bot to handle situations where it may need guidance or verification before proceeding.\n",
    "  \n",
    "Check out the code snippet below to review our graph from this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5baedc29-0087-44a3-ab0c-ae82ab6c069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd48652-7bb6-4e3b-97de-be7e7158708d",
   "metadata": {},
   "source": [
    "## Part 4: Human-in-the-loop\n",
    "\n",
    "Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before executing to ensure that everything is working as intended.\n",
    "\n",
    "LangGraph supports `human-in-the-loop` workflows in a number of ways. In this section, we will use LangGraph's `interrupt_before` functionality to always break at the tool node.\n",
    "\n",
    "First, start from our existing code. The following is copied from Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b82cf61-4647-43fb-ace9-bb4b5fc3d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(state[\"messages\"])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7f6cf-a3df-4608-b9e4-5814f4e57d22",
   "metadata": {},
   "source": [
    "Now, compile the graph, specifying to `interrupt_before` the `action` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdd0546f-40bd-4403-9f7f-a91f4e38aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,    \n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ff0772a-52a1-40da-92bb-6a5a904d8d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the weather in Kuala Lumpur?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (2ea85c39-bb4c-4978-a2ee-54c21e426fd5)\n",
      " Call ID: 2ea85c39-bb4c-4978-a2ee-54c21e426fd5\n",
      "  Args:\n",
      "    query: weather in Kuala Lumpur\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the weather in Kuala Lumpur?\"\n",
    "config = {\n",
    "    \"configurable\": {\"thread_id\": \"1\"}\n",
    "}\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    input={\n",
    "        \"messages\": [(\"user\", user_input)]\n",
    "    }, \n",
    "    config=config, \n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd7452-c713-482f-906d-acb377751dc1",
   "metadata": {},
   "source": [
    "Let's inspect the graph state to confirm it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb3b8d4a-c9b3-4d90-9930-a6a1bde02894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ae8fb-b267-4c33-88a3-e32054bca07a",
   "metadata": {},
   "source": [
    "**Notice** the `next` node is set to **`tools`**. We've interrupted it **before** the `tools` node! Let's check the tool invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c74c9faf-7210-4879-8c4e-412822f58aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'weather in Kuala Lumpur'},\n",
       "  'id': '2ea85c39-bb4c-4978-a2ee-54c21e426fd5'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1e423-3a31-464c-abc5-240d05c2e4dc",
   "metadata": {},
   "source": [
    "This query seems reasonable. Nothing to filter here. The simplest thing the human can do is just let the graph continue executing. Let's do that below.\n",
    "\n",
    "Next, continue the graph! Passing in `None` will just let the graph continue where it left off, without adding anything new to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9576a4a-2be2-4e69-932d-630c154a17eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.met.gov.my/en/forecast/weather/town/\", \"content\": \"Location : Kuala Lumpur. Date Weather Forecast; 20/06/2024 Thursday Thunderstorms Morning: Thunderstorms Afternoon: Thunderstorms Night: No rain Min: 24 ... 25/06/2024 Tuesday Thunderstorms Morning: Thunderstorms Afternoon: No rain Night: No rain Min: 24\\u00b0C Max: 34\\u00b0C\"}, {\"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'Kuala Lumpur', 'region': 'Kuala Lumpur', 'country': 'Malaysia', 'lat': 3.17, 'lon': 101.7, 'tz_id': 'Asia/Kuala_Lumpur', 'localtime_epoch': 1719295963, 'localtime': '2024-06-25 14:12'}, 'current': {'last_updated_epoch': 1719295200, 'last_updated': '2024-06-25 14:00', 'temp_c': 32.7, 'temp_f': 90.8, 'is_day': 1, 'condition': {'text': 'Patchy rain nearby', 'icon': '//cdn.weatherapi.com/weather/64x64/day/176.png', 'code': 1063}, 'wind_mph': 4.9, 'wind_kph': 7.9, 'wind_degree': 202, 'wind_dir': 'SSW', 'pressure_mb': 1007.0, 'pressure_in': 29.74, 'precip_mm': 0.04, 'precip_in': 0.0, 'humidity': 54, 'cloud': 86, 'feelslike_c': 37.3, 'feelslike_f': 99.1, 'windchill_c': 32.7, 'windchill_f': 90.8, 'heatindex_c': 37.3, 'heatindex_f': 99.1, 'dewpoint_c': 22.3, 'dewpoint_f': 72.1, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 7.0, 'gust_mph': 5.7, 'gust_kph': 9.1}}\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The weather in Kuala Lumpur is currently Patchy rain nearby with a temperature of 32.7 degrees Celsius. The feels like temperature is 37.3 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "# `None` will append nothing new to the current state, letting it \n",
    "# resume as if it had never been interrupted.\n",
    "events = graph.stream(\n",
    "    input=None, \n",
    "    config=config, \n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6395b83-b8f2-43fa-9433-ac9a43223c0d",
   "metadata": {},
   "source": [
    "**Congrats!** We've used an `interrupt` to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since we have already added a **checkpointer**, the graph can be paused **indefinitely** and resumed at any time as if nothing had happened.\n",
    "\n",
    "Next, we'll explore how to further customize the bot's behavior using custom state updates.\n",
    "\n",
    "Below is a copy of the code you used in this section. The only difference between this and the previous parts is the addition of the `interrupt_before` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81f56786-0016-4b72-b20f-0e3b767221d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(node=\"chatbot\", action=chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(node=\"tools\", action=tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    source=\"chatbot\",\n",
    "    path=tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\n",
    "    start_key=\"tools\", \n",
    "    end_key=\"chatbot\"\n",
    ")\n",
    "graph_builder.set_entry_point(key=\"chatbot\")\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    \n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf27557-516e-45c5-abc7-64334e0b9be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
